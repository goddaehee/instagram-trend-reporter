"""Apifyë¥¼ ì‚¬ìš©í•œ ì¸ìŠ¤íƒ€ê·¸ë¨ ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ"""
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from apify_client import ApifyClient

from .config import get_config, Config
from .credentials import get_apify_token


class FetcherError(Exception):
    """ìŠ¤í¬ë˜í¼ ì‹¤í–‰ ì¤‘ ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜"""
    pass


class InstagramFetcher:
    """ì¸ìŠ¤íƒ€ê·¸ë¨ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, config: Optional[Config] = None):
        self.config = config or get_config()
        # í™˜ê²½ë³€ìˆ˜/Secretsì—ì„œ í† í° ìš°ì„  í™•ì¸
        apify_token = get_apify_token() or self.config.apify_token
        if not apify_token:
            raise ValueError("APIFY_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        self.client = ApifyClient(apify_token)
    
    def fetch_profiles(self, usernames: List[str]) -> Dict[str, Any]:
        """í”„ë¡œí•„ ë°ì´í„° ìˆ˜ì§‘"""
        print(f"í”„ë¡œí•„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘: {', '.join(usernames)}")

        scraper_cfg = self.config.scraper

        run_input = {
            "usernames": usernames,
        }

        try:
            run = self.client.actor("apify/instagram-profile-scraper").call(
                run_input=run_input,
                timeout_secs=scraper_cfg.timeout_secs,
                max_total_charge_usd=scraper_cfg.max_cost_usd,
            )
        except Exception as e:
            raise FetcherError(f"í”„ë¡œí•„ ìŠ¤í¬ë˜í¼ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        
        profiles = {}
        for item in self.client.dataset(run["defaultDatasetId"]).iterate_items():
            username = item.get("username", "").lower()
            profiles[username] = item
        
        print(f"  â†’ {len(profiles)}ê°œ í”„ë¡œí•„ ìˆ˜ì§‘ ì™„ë£Œ")
        return profiles
    
    # 30ì¼ ì´ˆê³¼ ê¸°ê°„ì€ ìë™ ë¶„í• 
    MAX_CHUNK_DAYS = 30

    def fetch_posts(
        self,
        usernames: List[str],
        days: int = 7,
        content_type: str = "reels",
        limit_per_account: int = 50,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """í¬ìŠ¤íŠ¸/ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘

        start_date/end_dateê°€ ì§€ì •ë˜ë©´ í•´ë‹¹ ê¸°ê°„, ì•„ë‹ˆë©´ ìµœê·¼ daysì¼ ê¸°ì¤€.
        30ì¼ ì´ˆê³¼ ê¸°ê°„ì€ ìë™ìœ¼ë¡œ 30ì¼ ë‹¨ìœ„ë¡œ ë¶„í•  ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        """
        if start_date and end_date:
            since_date = datetime.strptime(start_date, "%Y-%m-%d")
            until_date = datetime.strptime(end_date, "%Y-%m-%d").replace(hour=23, minute=59, second=59)
        else:
            since_date = datetime.now() - timedelta(days=days)
            until_date = datetime.now()

        total_days = (until_date - since_date).days

        # 30ì¼ ì´í•˜ë©´ ë‹¨ì¼ ì‹¤í–‰
        if total_days <= self.MAX_CHUNK_DAYS:
            print(f"ì½˜í…ì¸  ìˆ˜ì§‘ ì¤‘: {content_type}, {total_days}ì¼ ({since_date.strftime('%Y-%m-%d')} ~ {until_date.strftime('%Y-%m-%d')})")
            return self._fetch_posts_chunk(
                usernames, content_type, limit_per_account, since_date, until_date
            )

        # 30ì¼ ì´ˆê³¼ë©´ ì²­í¬ ë¶„í• 
        chunks = []
        chunk_start = since_date
        while chunk_start < until_date:
            chunk_end = min(chunk_start + timedelta(days=self.MAX_CHUNK_DAYS), until_date)
            chunks.append((chunk_start, chunk_end))
            chunk_start = chunk_end + timedelta(seconds=1)

        print(f"ì½˜í…ì¸  ìˆ˜ì§‘ ì¤‘: {content_type}, {total_days}ì¼ â†’ {len(chunks)}íšŒ ë¶„í•  ìˆ˜ì§‘")

        all_posts = []
        failed_chunks = []
        for i, (c_start, c_end) in enumerate(chunks, 1):
            chunk_days = (c_end - c_start).days
            print(f"\n  ğŸ“¦ [{i}/{len(chunks)}] {c_start.strftime('%Y-%m-%d')} ~ {c_end.strftime('%Y-%m-%d')} ({chunk_days}ì¼)")
            try:
                chunk_posts = self._fetch_posts_chunk(
                    usernames, content_type, limit_per_account, c_start, c_end
                )
                all_posts.extend(chunk_posts)
                print(f"  ğŸ“¦ [{i}/{len(chunks)}] ëˆ„ì : {len(all_posts)}ê°œ")
            except FetcherError as e:
                failed_chunks.append((i, c_start, c_end, str(e)))
                print(f"  âš ï¸ [{i}/{len(chunks)}] ì²­í¬ ì‹¤íŒ¨: {e}")

        if failed_chunks and not all_posts:
            raise FetcherError(
                f"ëª¨ë“  ì²­í¬ ìˆ˜ì§‘ ì‹¤íŒ¨ ({len(failed_chunks)}/{len(chunks)}). "
                f"ì²« ì˜¤ë¥˜: {failed_chunks[0][3]}"
            )
        if failed_chunks:
            print(f"\n  âš ï¸ {len(failed_chunks)}/{len(chunks)} ì²­í¬ ì‹¤íŒ¨ (ìˆ˜ì§‘ëœ ë°ì´í„°ë¡œ ê³„ì† ì§„í–‰)")

        # ì¤‘ë³µ ì œê±° (URL ê¸°ì¤€)
        seen_urls = set()
        unique_posts = []
        for post in all_posts:
            url = post.get("url", post.get("id", id(post)))
            if url not in seen_urls:
                seen_urls.add(url)
                unique_posts.append(post)

        if len(all_posts) != len(unique_posts):
            print(f"  â†’ ì¤‘ë³µ ì œê±°: {len(all_posts)}ê°œ â†’ {len(unique_posts)}ê°œ")

        print(f"\nâœ… ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {len(unique_posts)}ê°œ ({len(chunks)}íšŒ ë¶„í• )")
        return unique_posts

    def _fetch_posts_chunk(
        self,
        usernames: List[str],
        content_type: str,
        limit_per_account: int,
        since_date: datetime,
        until_date: datetime,
    ) -> List[Dict[str, Any]]:
        """ë‹¨ì¼ ê¸°ê°„ í¬ìŠ¤íŠ¸ ìˆ˜ì§‘ (ë‚´ë¶€ ë©”ì„œë“œ)"""
        # ì½˜í…ì¸  íƒ€ì…ì— ë”°ë¥¸ URL ìƒì„±
        direct_urls = []
        for username in usernames:
            if content_type == "reels":
                direct_urls.append(f"https://www.instagram.com/{username}/reels/")
            else:
                direct_urls.append(f"https://www.instagram.com/{username}/")

        scraper_cfg = self.config.scraper

        # ê³¼ê±° ê¸°ê°„ ìš”ì²­ ì‹œ limit ìë™ ì¦ê°€
        # resultsLimitì€ ë‚ ì§œ í•„í„°ë³´ë‹¤ ë¨¼ì € ì ìš©ë˜ë¯€ë¡œ, í˜„ì¬~since_date ì‚¬ì´
        # í¬ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ í¬í•¨í•  ë§Œí¼ ì¶©ë¶„íˆ ë†’ì—¬ì•¼ í•¨
        days_ago = (datetime.now() - since_date).days
        if days_ago > 14:
            adjusted_limit = max(limit_per_account, days_ago * 5)
            adjusted_limit = min(adjusted_limit, 500)  # ë¹„ìš© ìƒí•œ
        else:
            adjusted_limit = limit_per_account

        run_input = {
            "directUrls": direct_urls,
            "resultsLimit": adjusted_limit,
            "resultsType": "posts" if content_type != "stories" else "stories",
            "searchType": "user",
            "onlyPostsNewerThan": since_date.strftime("%Y-%m-%d"),
            # NOTE: apify/instagram-scraperëŠ” maxRequestRetriesë¥¼ ê³µì‹ inputìœ¼ë¡œ
            # ë…¸ì¶œí•˜ì§€ ì•Šì•„ ë¬´ì‹œë  ìˆ˜ ìˆìŒ. ì‹¤ì§ˆì  ë°©ì–´ëŠ” timeout_secsì™€ max_total_charge_usd.
            "maxRequestRetries": scraper_cfg.max_request_retries,
            "maxConcurrency": scraper_cfg.max_concurrency,
        }

        if adjusted_limit != limit_per_account:
            print(f"    â„¹ï¸ ê³¼ê±° ê¸°ê°„({days_ago}ì¼ ì „) â†’ resultsLimit {limit_per_account} â†’ {adjusted_limit} ìë™ ì¡°ì •")

        # ë™ì  íƒ€ì„ì•„ì›ƒ: ê¸°ë³¸ + ê³„ì • ìˆ˜ ë¹„ë¡€
        timeout = scraper_cfg.timeout_secs + (len(usernames) * scraper_cfg.timeout_per_account_secs)
        timeout = min(timeout, 900)  # ìµœëŒ€ 15ë¶„

        try:
            run = self.client.actor("apify/instagram-scraper").call(
                run_input=run_input,
                timeout_secs=timeout,
                max_total_charge_usd=scraper_cfg.max_cost_usd,
            )
        except Exception as e:
            raise FetcherError(f"Apify ìŠ¤í¬ë˜í¼ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

        posts = []
        total_items = 0
        for item in self.client.dataset(run["defaultDatasetId"]).iterate_items():
            total_items += 1
            # ë‚ ì§œ í•„í„°ë§
            timestamp = item.get("timestamp")
            if timestamp:
                try:
                    post_date = datetime.fromisoformat(timestamp.replace("Z", "+00:00"))
                    post_date_naive = post_date.replace(tzinfo=None)
                    if post_date_naive < since_date:
                        continue
                    if post_date_naive > until_date:
                        continue
                except (ValueError, TypeError):
                    pass

            posts.append(item)

        print(f"    â†’ {len(posts)}ê°œ ì½˜í…ì¸  (ì „ì²´ {total_items}ê°œ ì¤‘ ê¸°ê°„ ë‚´ í•„í„°)")

        # Circuit Breaker: ìˆ˜ì§‘ ê²°ê³¼ ê²€ì¦
        min_threshold = self.config.scraper.min_results_threshold
        if total_items == 0:
            raise FetcherError(
                "ìˆ˜ì§‘ ì™„ì „ ì‹¤íŒ¨: ìŠ¤í¬ë˜í¼ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. "
                "API í† í° ë˜ëŠ” ê³„ì •ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        if total_items > 0 and len(posts) == 0:
            print("    âš ï¸ ìˆ˜ì§‘ëœ ì½˜í…ì¸ ê°€ ëª¨ë‘ ì§€ì • ê¸°ê°„ ë°–ì…ë‹ˆë‹¤.")
        elif len(posts) < min_threshold:
            print(f"    âš ï¸ ìˆ˜ì§‘ëŸ‰ì´ ìµœì†Œ ê¸°ì¤€({min_threshold}ê°œ) ë¯¸ë§Œì…ë‹ˆë‹¤ ({len(posts)}ê°œ).")

        return posts
    
    def fetch_all(self) -> Dict[str, Any]:
        """ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ (í”„ë¡œí•„ + í¬ìŠ¤íŠ¸)"""
        usernames = [a.username for a in self.config.accounts]
        
        # í”„ë¡œí•„ ìˆ˜ì§‘
        profiles = self.fetch_profiles(usernames)
        
        # í¬ìŠ¤íŠ¸ ìˆ˜ì§‘
        posts = self.fetch_posts(
            usernames=usernames,
            days=self.config.analysis.days,
            content_type=self.config.analysis.content_type,
            limit_per_account=self.config.analysis.limit_per_account,
            start_date=self.config.analysis.start_date,
            end_date=self.config.analysis.end_date,
        )
        
        return {
            "profiles": profiles,
            "posts": posts,
            "metadata": {
                "fetched_at": datetime.now().isoformat(),
                "days": self.config.analysis.days,
                "content_type": self.config.analysis.content_type,
                "accounts": usernames,
                "total_posts": len(posts),
            }
        }


def validate_fetch_quality(posts: List[Dict[str, Any]], num_accounts: int) -> Dict[str, Any]:
    """ìˆ˜ì§‘ ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
    total = len(posts)
    if total == 0:
        return {"valid": False, "issues": ["ìˆ˜ì§‘ëœ í¬ìŠ¤íŠ¸ ì—†ìŒ"], "stats": {}}

    with_caption = sum(1 for p in posts if p.get("caption"))
    with_engagement = sum(1 for p in posts if p.get("likesCount") or p.get("videoPlayCount"))

    stats = {
        "total_posts": total,
        "caption_rate": with_caption / total,
        "engagement_rate": with_engagement / total,
    }

    issues = []
    if total < num_accounts * 2:
        issues.append(f"í¬ìŠ¤íŠ¸ ë¶€ì¡±: {total}ê°œ (ê³„ì •ë‹¹ ìµœì†Œ 2ê°œ = {num_accounts * 2}ê°œ ê¸°ëŒ€)")
    if stats["caption_rate"] < 0.3:
        issues.append(f"ìº¡ì…˜ ë¹„ìœ¨ ë‚®ìŒ: {stats['caption_rate']:.0%} (í•´ì‹œíƒœê·¸ ë¶„ì„ ì œí•œì )")
    if stats["engagement_rate"] < 0.5:
        issues.append(f"ì¸ê²Œì´ì§€ë¨¼íŠ¸ ë°ì´í„° ë¶€ì¡±: {stats['engagement_rate']:.0%} (ë­í‚¹ ì‹ ë¢°ë„ ë‚®ìŒ)")

    if issues:
        for issue in issues:
            print(f"  âš ï¸ ë°ì´í„° í’ˆì§ˆ: {issue}")

    return {
        "valid": total >= num_accounts and not issues,
        "issues": issues,
        "stats": stats,
    }


def fetch_instagram_data(config: Optional[Config] = None) -> Dict[str, Any]:
    """ì¸ìŠ¤íƒ€ê·¸ë¨ ë°ì´í„° ìˆ˜ì§‘ (í¸ì˜ í•¨ìˆ˜)"""
    fetcher = InstagramFetcher(config)
    return fetcher.fetch_all()
